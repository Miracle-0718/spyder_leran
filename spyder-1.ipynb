{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 超级简单的初次爬虫尝试\n",
    "    为了数据库大作业搞点数据\n",
    "    - 模仿豆瓣爬虫教程：https://www.bilibili.com/video/BV12E411A7ZQ?share_source=copy_web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - 目标网站：https://www.cnhnb.com/supply/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base64 import decode\n",
    "import bs4\n",
    "import re\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "import urllib.parse\n",
    "import xlwt\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def askURL(url):\n",
    "    '''\n",
    "    得到一个指定的URL的页面内容\n",
    "    '''\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:99.0) Gecko/20100101 Firefox/99.0\"\n",
    "    }\n",
    "    req = urllib.request.Request(url=url,headers=headers)\n",
    "    try:\n",
    "        response = urllib.request.urlopen(req)\n",
    "        html=response.read().decode(\"utf-8\")\n",
    "        \n",
    "    except urllib.error.URLError as e:\n",
    "        if hasattr(e,\"code\"):\n",
    "            print(e.code)\n",
    "        if hasattr(e,\"reason\"):\n",
    "            print(e.reason)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - 图片好像是动态加载/懒加载？的 不知道怎么爬 以后再学"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#商品图片\n",
    "# findImageLink = re.compile(r'<img.*src=\"(.*?)\"',re.S) \n",
    "\n",
    "findtitle = re.compile(r'<img alt=\"(.*)\" data-v-71cf4cda=\"\" title=\"',re.S)\n",
    "findprice = re.compile(r'<span class=\"sp1\" data-v-71cf4cda=\"\">(.*)</span>')\n",
    "findlocation = re.compile(r'<div class=\"r-shop-btm\" data-v-71cf4cda=\"\">(.*?)</div>')\n",
    "findshop = re.compile(r'<div class=\"l-shop-btm\" data-v-71cf4cda=\"\">(.*?)</div>')\n",
    "findturnover = re.compile(r'<div class=\"turnover\" data-v-71cf4cda=\"\">(.*?)</div>',re.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(html):\n",
    "    datalist=[]\n",
    "    soup =bs4.BeautifulSoup(html,\"html.parser\")\n",
    "    for item in soup.find_all('div',class_=\"show-ctn\"): #查找网页显示的列表中的一个item\n",
    "        # print(item)\n",
    "        data = []\n",
    "        \n",
    "        item = str(item) \n",
    "\n",
    "        # imagelink = re.findall(findImageLink,item)[0]\n",
    "        # data.append(imagelink)  \n",
    "\n",
    "        title =re.findall(findtitle,item)[0]\n",
    "        data.append(title)\n",
    "\n",
    "        price = re.findall(findprice,item)[0]\n",
    "        data.append(price)  \n",
    "\n",
    "        location = re.findall(findlocation,item)[0]\n",
    "        data.append(location)  \n",
    "\n",
    "        shop = re.findall(findshop,item)[0]\n",
    "        data.append(shop) \n",
    "\n",
    "        turnover = re.findall(findturnover,item)[0].replace('\\n', '').strip()\n",
    "        data.append(turnover)\n",
    "\n",
    "        datalist.append(data)\n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(datalist,savepath):\n",
    "    '''\n",
    "    保存数据到文件savepath\n",
    "    '''\n",
    "    print(\"save...\")\n",
    "    book = xlwt.Workbook(encoding=\"utf-8\",style_compression=0)\n",
    "    sheet = book.add_sheet('水果',cell_overwrite_ok=True)\n",
    "    col = (\"title\",\"price\",\"location\",\"shop\",\"turnpver\")\n",
    "    for i in range(0,5):\n",
    "        sheet.write(0,i,col[i])\n",
    "    for i in range(len(datalist)):\n",
    "        data=datalist[i]\n",
    "        for j in range(0,5):\n",
    "            sheet.write(i+1,j,data[j])\n",
    "    book.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save...\n"
     ]
    }
   ],
   "source": [
    "html=askURL(\"https://www.cnhnb.com/p/sgzw/\")\n",
    "datalist=getData(html)\n",
    "\n",
    "savepath = \"农产品.xls\"\n",
    "saveData(datalist,savepath)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16f5b46f222e2a3e8d4adbf7141cae37b71ed37616e60735fa5d1164a1bc3ada"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
